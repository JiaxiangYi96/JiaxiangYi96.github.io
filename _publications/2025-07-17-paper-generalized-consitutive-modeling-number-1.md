---
title: "Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement"
collection: publications
category: manuscripts
permalink: /publication/2025-07-17-multi-fidelity-history-dependent-learning
excerpt: "This work generalizes data-driven learning to history‐dependent multi-fidelity settings, enabling uncertainty quantification and disentanglement of model vs noise."
date: 2025-07-17
venue: "arXiv preprint"
paperurl: "https://arxiv.org/abs/2507.13416"
bibtexurl: "https://arxiv.org/bibtex/2507.13416"
citation: "Yi, J., Ferreira, B. P., & Bessa, M. A. (2025). “Single- to multi-fidelity history-dependent learning with uncertainty quantification and disentanglement.” *arXiv preprint arXiv:2507.13416*."

---
Data-driven learning is generalized to consider history-dependent multi-fidelity data, while quantifying epistemic uncertainty and disentangling it from data noise (aleatoric uncertainty). This generalization is hierarchical and adapts to different learning scenarios: from training the simplest single-fidelity deterministic neural networks up to the proposed multi-fidelity variance estimation Bayesian recurrent neural networks. The proposed methodology is demonstrated by applying it to different data-driven constitutive modeling scenariosfor history-dependent plasticity of elastoplastic biphasic materials  that include multiple fidelities with and without aleatoric uncertainty (noise). The method accurately predicts the response and quantifies model error while also discovering the noise distribution (when present). The versatility and generality of the proposed method open opportunities for future real-world applications in diverse scientific and engineering domains; especially, the most challenging cases involving design and analysis under uncertainty.
